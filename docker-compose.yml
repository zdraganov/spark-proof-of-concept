version: '3'
services:
  zookeeper:
    image: "wurstmeister/zookeeper"
    ports:
      - "2181:2181"

  kafka:
    image: "wurstmeister/kafka"
    environment:
      KAFKA_ADVERTISED_HOST_NAME: "kafka"
      KAFKA_ADVERTISED_PORT: "9092"
      KAFKA_ZOOKEEPER_CONNECT: "zookeeper:2181"
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'true'
      KAFKA_CREATE_TOPICS: "raw_data:1:1,aggregated_data:1:1"
    volumes:
      - /private/var/run/docker.sock:/var/run/docker.sock
    ports:
      - "9092:9092"
    links:
      - zookeeper
    depends_on:
      - zookeeper

  producer:
    image : "producer_test:latest"
    environment:
      KAFKA_HOST: "kafka"
      KAFKA_PORT: "9092"
      RAW_DATA_TOPIC: "raw_data"
    volumes:
      - ./producer/producer.py:/usr/app/src/producer.py
    command: python -u /usr/app/src/producer.py
    links:
      - kafka
      - zookeeper
    depends_on:
      - kafka

  consumer:
    image: "consumer_test:latest"
    environment:
      KAFKA_HOST: "kafka"
      KAFKA_PORT: "9092"
      RAW_DATA_TOPIC: "raw_data"
      AGGREGATED_DATA_TOPIC: "aggregated_data"
    volumes:
      - ./consumer/consumer.py:/usr/app/src/consumer.py
    command: python -u /usr/app/src/consumer.py
    links:
      - kafka
      - zookeeper
    depends_on:
      - kafka

  spark-master:
    image: bde2020/spark-master:2.1.1-hadoop2.7
    container_name: spark-master
    ports:
      - "8080:8080"
      - "7077:7077"
    environment:
      - INIT_DAEMON_STEP=setup_spark
      - "constraint:node==<yourmasternode>"
    links:
      - kafka

  spark-worker-1:
    image: bde2020/spark-worker:2.1.1-hadoop2.7
    container_name: spark-worker-1
    depends_on:
      - spark-master
    ports:
      - "8082:8082"
    environment:
      - "SPARK_MASTER=spark://spark-master:7077"
      - "constraint:node==<yourmasternode>"


  # sparkmaster:
  #   image: gettyimages/spark
  #   command: bin/spark-class org.apache.spark.deploy.master.Master -h master
  #   hostname: master
  #   environment:
  #     MASTER: spark://master:7077
  #     SPARK_CONF_DIR: /conf
  #     SPARK_PUBLIC_DNS: localhost
  #   links:
  #     - kafka
  #   expose:
  #     - 7001
  #     - 7002
  #     - 7003
  #     - 7004
  #     - 7005
  #     - 7006
  #     - 7077
  #     - 6066
  #   ports:
  #     - 4040:4040
  #     - 6066:6066
  #     - 7077:7077
  #     - 8080:8080
  #   volumes:
  #     - ./conf/master:/conf
  #     - ./data:/tmp/data

  # sparkworker:
  #   image: gettyimages/spark
  #   command: bin/spark-class org.apache.spark.deploy.worker.Worker spark://master:7077
  #   hostname: worker
  #   environment:
  #     SPARK_CONF_DIR: /conf
  #     SPARK_WORKER_CORES: 2
  #     SPARK_WORKER_MEMORY: 1g
  #     SPARK_WORKER_PORT: 8881
  #     SPARK_WORKER_WEBUI_PORT: 8081
  #     SPARK_PUBLIC_DNS: localhost
  #   links:
  #     - sparkmaster
  #   expose:
  #     - 7012
  #     - 7013
  #     - 7014
  #     - 7015
  #     - 7016
  #     - 8881
  #   ports:
  #     - 8081:8081
  #   volumes:
  #     - ./conf/worker:/conf
  #     - ./data:/tmp/data